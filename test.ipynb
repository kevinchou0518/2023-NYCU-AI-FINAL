{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/KevinChou/.cache/huggingface/datasets/json/default-6a36e5922eb05f45/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb4c495fa4d4f8287fe5f7906403820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/KevinChou/.cache/huggingface/datasets/json/default-891c751e5dc163e9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37c3d2a57d84c17a3c1c9625625d6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/KevinChou/.cache/huggingface/datasets/json/default-0cae1a5ed046e7ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da40577f299a45eea61c1c096803f6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\KevinChou\\.cache\\huggingface\\datasets\\json\\default-6a36e5922eb05f45\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-f294d5c24e8bbee2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\KevinChou\\.cache\\huggingface\\datasets\\json\\default-0cae1a5ed046e7ee\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-40c0019c2c1d69f4.arrow\n",
      "Loading cached processed dataset at C:\\Users\\KevinChou\\.cache\\huggingface\\datasets\\json\\default-891c751e5dc163e9\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-a3e539b82b39e4b2.arrow\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datasets \n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_MAPPING,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"train.json\")\n",
    "dataset_test = load_dataset(\"json\", data_files=\"test.json\")\n",
    "dataset_eval = load_dataset(\"json\", data_files=\"eval.json\")\n",
    "dataset['eval'] = dataset_eval['train']\n",
    "dataset['test'] = dataset_test['train']\n",
    "dataset\n",
    "mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "def tokenize_sample_data(data):\n",
    "  # Max token size is 14536 and 215 for inputs and labels, respectively.\n",
    "  # Here I restrict these token size.\n",
    "  input_feature = mt5_tokenizer(data[\"article\"], truncation=True, max_length=256)\n",
    "  label = mt5_tokenizer(data[\"title\"], truncation=True, max_length=64)\n",
    "  return {\n",
    "    \"input_ids\": input_feature[\"input_ids\"],\n",
    "    \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "    \"labels\": label[\"input_ids\"],\n",
    "  }\n",
    "\n",
    "tokenized_ds = dataset.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"title\", \"url\", \"article\"],\n",
    "  batched=True,\n",
    "  batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# define function for custom tokenization\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = mt5_tokenizer(arg)\n",
    "  return mt5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "# define function to get ROUGE scores with custom tokenization\n",
    "def metrics_func(eval_arg):\n",
    "  preds, labels = eval_arg\n",
    "  labels = np.where(labels != -100, labels, mt5_tokenizer.pad_token_id)\n",
    "  text_preds = mt5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  text_labels = mt5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "  text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "  sent_tokenizer_tw = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(p))) for p in text_preds]\n",
    "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(l))) for l in text_labels]\n",
    "  # compute ROUGE score with custom tokenization\n",
    "\n",
    "  return rouge_metric.compute(\n",
    "    predictions=text_preds,\n",
    "    references=text_labels,\n",
    "    tokenizer=tokenize_sentence\n",
    "  )\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_config = AutoConfig.from_pretrained(\n",
    "  \"google/mt5-small\",\n",
    "  max_length=128,\n",
    "  length_penalty=0.6,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_beams=10,\n",
    ")\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"google/mt5-small\", config=mt5_config)\n",
    "         .to(device))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  mt5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 756/756 [22:10<00:00,  1.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.1406464367690917,\n",
       " 'rouge2': 0.06483060634646234,\n",
       " 'rougeL': 0.1382132647823016,\n",
       " 'rougeLsum': 0.13735610576505136}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(len(sample_dataloader))\n",
    "\n",
    "count = 0\n",
    "total_metrice = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "for batch in tqdm(sample_dataloader):\n",
    "  #print(batch)\n",
    "  count += 1\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"].to(device),\n",
    "      num_beams=10,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=64,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  met = metrics_func([preds, labels])\n",
    "  total_metrice['rouge1'] += met['rouge1']\n",
    "  total_metrice['rouge2'] += met['rouge2']\n",
    "  total_metrice['rougeL'] += met['rougeL']\n",
    "  total_metrice['rougeLsum'] += met['rougeLsum']\n",
    "total_metrice['rouge1'] /= count\n",
    "total_metrice['rouge2'] /= count\n",
    "total_metrice['rougeL'] /= count\n",
    "total_metrice['rougeLsum'] /= count\n",
    "total_metrice\n",
    "#metrics_func([preds, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_config = AutoConfig.from_pretrained(\n",
    "  \"google/mt5-small\",\n",
    "  max_length=128,\n",
    "  length_penalty=0.6,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_beams=10,\n",
    ")\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"./iter_trained_for_summarization_tw\", config=mt5_config)\n",
    "         .to(device))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  mt5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 756/756 [27:09<00:00,  2.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.44033605066969383,\n",
       " 'rouge2': 0.22614575892683023,\n",
       " 'rougeL': 0.3753717622318992,\n",
       " 'rougeLsum': 0.4061266685861491}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "#metrics_func([preds, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_project\\AI_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import evaluate\n",
    "\n",
    "mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = mt5_tokenizer(arg)\n",
    "  return mt5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "def eval_func(eval_arg):\n",
    "    text_preds, text_labels = eval_arg\n",
    "    text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "    text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "    sent_tokenizer_tw = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "    text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(p))) for p in text_preds]\n",
    "    text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(l))) for l in text_labels]\n",
    "    return rouge_metric.compute(\n",
    "        predictions=text_preds,\n",
    "        references=text_labels,\n",
    "        tokenizer=tokenize_sentence\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3777/3777 [00:00<00:00, 378584.93it/s]\n",
      "3777it [06:00, 10.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.2460162917745359,\n",
       " 'rouge2': 0.10518923260157499,\n",
       " 'rougeL': 0.2141261966007162,\n",
       " 'rougeLsum': 0.2214723665038855}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import eval\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "topic_labels = []\n",
    "topic_prebs = []\n",
    "with open(\"extract.json\", encoding='utf-8') as file:\n",
    "    datas = list(file)\n",
    "total_metrice_extract = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "for data in tqdm(datas):\n",
    "    data = json.loads(data)\n",
    "    topic_labels.append(data[\"old_title\"])\n",
    "    topic_prebs.append(data[\"new_title\"])\n",
    "#topic_labels\n",
    "#topic_prebs\n",
    "count = 0\n",
    "for label, prebs in tqdm(zip(topic_labels, topic_prebs)):\n",
    "    label = [label]\n",
    "    prebs = [prebs]\n",
    "    met = eval_func([prebs, label])\n",
    "    count += 1\n",
    "    total_metrice_extract['rouge1'] += met['rouge1']\n",
    "    total_metrice_extract['rouge2'] += met['rouge2']\n",
    "    total_metrice_extract['rougeL'] += met['rougeL']\n",
    "    total_metrice_extract['rougeLsum'] += met['rougeLsum']\n",
    "    #print(score)\n",
    "total_metrice_extract['rouge1'] /= count\n",
    "total_metrice_extract['rouge2'] /= count\n",
    "total_metrice_extract['rougeL'] /= count\n",
    "total_metrice_extract['rougeLsum'] /= count\n",
    "total_metrice_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_config = AutoConfig.from_pretrained(\n",
    "  \"google/mt5-small\",\n",
    "  max_length=128,\n",
    "  length_penalty=0.6,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_beams=10,\n",
    ")\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"./mlplusrl_iter_trained_for_summarization_tw\", config=mt5_config)\n",
    "         .to(device))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  mt5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/756 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "d:\\AI_project\\AI_env\\lib\\site-packages\\transformers\\generation\\utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "100%|██████████| 756/756 [25:58<00:00,  2.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.38985323082078915,\n",
       " 'rouge2': 0.19369648216142504,\n",
       " 'rougeL': 0.34375745564642174,\n",
       " 'rougeLsum': 0.36101202341006955}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(len(sample_dataloader))\n",
    "count = 0\n",
    "total_metrice = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "for batch in tqdm(sample_dataloader):\n",
    "  #print(batch)\n",
    "  count += 1\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"].to(device),\n",
    "      num_beams=10,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=64,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  met = metrics_func([preds, labels])\n",
    "  total_metrice['rouge1'] += met['rouge1']\n",
    "  total_metrice['rouge2'] += met['rouge2']\n",
    "  total_metrice['rougeL'] += met['rougeL']\n",
    "  total_metrice['rougeLsum'] += met['rougeLsum']\n",
    "total_metrice['rouge1'] /= count\n",
    "total_metrice['rouge2'] /= count\n",
    "total_metrice['rougeL'] /= count\n",
    "total_metrice['rougeLsum'] /= count\n",
    "total_metrice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
