{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/KevinChou/.cache/huggingface/datasets/json/default-6a36e5922eb05f45/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b123c3d6f534fd1b65a9fc032d2fea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/KevinChou/.cache/huggingface/datasets/json/default-891c751e5dc163e9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee9ca02e85a49d09614f97dd2feb731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/KevinChou/.cache/huggingface/datasets/json/default-0cae1a5ed046e7ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb212b2fcccd41759c28f075c2ec9966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_project\\AI_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Loading cached processed dataset at C:\\Users\\KevinChou\\.cache\\huggingface\\datasets\\json\\default-6a36e5922eb05f45\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-f294d5c24e8bbee2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\KevinChou\\.cache\\huggingface\\datasets\\json\\default-0cae1a5ed046e7ee\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-40c0019c2c1d69f4.arrow\n",
      "Loading cached processed dataset at C:\\Users\\KevinChou\\.cache\\huggingface\\datasets\\json\\default-891c751e5dc163e9\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-a3e539b82b39e4b2.arrow\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datasets \n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    default_data_collator,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"train.json\")\n",
    "dataset_test = load_dataset(\"json\", data_files=\"test.json\")\n",
    "dataset_eval = load_dataset(\"json\", data_files=\"eval.json\")\n",
    "dataset['eval'] = dataset_eval['train']\n",
    "dataset['test'] = dataset_test['train']\n",
    "dataset\n",
    "mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "def tokenize_sample_data(data):\n",
    "  # Max token size is 14536 and 215 for inputs and labels, respectively.\n",
    "  # Here I restrict these token size.\n",
    "  input_feature = mt5_tokenizer(data[\"article\"], truncation=True, max_length=256)\n",
    "  label = mt5_tokenizer(data[\"title\"], truncation=True, max_length=64)\n",
    "  return {\n",
    "    \"input_ids\": input_feature[\"input_ids\"],\n",
    "    \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "    \"labels\": label[\"input_ids\"],\n",
    "  }\n",
    "\n",
    "tokenized_ds = dataset.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"title\", \"url\", \"article\"],\n",
    "  batched=True,\n",
    "  batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# define function for custom tokenization\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = mt5_tokenizer(arg)\n",
    "  return mt5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "# define function to get ROUGE scores with custom tokenization\n",
    "def metrics_func(eval_arg):\n",
    "  preds, labels = eval_arg\n",
    "  labels = np.where(labels != -100, labels, mt5_tokenizer.pad_token_id)\n",
    "  text_preds = mt5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  text_labels = mt5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "  text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "  sent_tokenizer_tw = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(p))) for p in text_preds]\n",
    "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(l))) for l in text_labels]\n",
    "  # compute ROUGE score with custom tokenization\n",
    "\n",
    "  return rouge_metric.compute(\n",
    "    predictions=text_preds,\n",
    "    references=text_labels,\n",
    "    tokenizer=tokenize_sentence\n",
    "  )\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import evaluate\n",
    "\n",
    "mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = mt5_tokenizer(arg)\n",
    "  return mt5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "def eval_func(eval_arg):\n",
    "    text_preds, text_labels = eval_arg\n",
    "    text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "    text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "    sent_tokenizer_tw = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "    text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(p))) for p in text_preds]\n",
    "    text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_tw.tokenize(l))) for l in text_labels]\n",
    "    return rouge_metric.compute(\n",
    "        predictions=text_preds,\n",
    "        references=text_labels,\n",
    "        tokenizer=tokenize_sentence\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3777/3777 [00:00<00:00, 344321.46it/s]\n",
      "3777it [06:19,  9.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.2460162917745359,\n",
       " 'rouge2': 0.10518923260157499,\n",
       " 'rougeL': 0.2141261966007162,\n",
       " 'rougeLsum': 0.2214723665038855}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import eval\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "topic_labels = []\n",
    "topic_prebs = []\n",
    "with open(\"extract.json\", encoding='utf-8') as file:\n",
    "    datas = list(file)\n",
    "total_metrice_extract = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "for data in tqdm(datas):\n",
    "    data = json.loads(data)\n",
    "    topic_labels.append(data[\"old_title\"])\n",
    "    topic_prebs.append(data[\"new_title\"])\n",
    "#topic_labels\n",
    "#topic_prebs\n",
    "count = 0\n",
    "for label, prebs in tqdm(zip(topic_labels, topic_prebs)):\n",
    "    label = [label]\n",
    "    prebs = [prebs]\n",
    "    met = eval_func([prebs, label])\n",
    "    count += 1\n",
    "    total_metrice_extract['rouge1'] += met['rouge1']\n",
    "    total_metrice_extract['rouge2'] += met['rouge2']\n",
    "    total_metrice_extract['rougeL'] += met['rougeL']\n",
    "    total_metrice_extract['rougeLsum'] += met['rougeLsum']\n",
    "    #print(score)\n",
    "total_metrice_extract['rouge1'] /= count\n",
    "total_metrice_extract['rouge2'] /= count\n",
    "total_metrice_extract['rougeL'] /= count\n",
    "total_metrice_extract['rougeLsum'] /= count\n",
    "total_metrice_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_config = AutoConfig.from_pretrained(\n",
    "    \"google/mt5-small\",\n",
    "    max_length=128,\n",
    "    length_penalty=0.6,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=10,  \n",
    ")\n",
    "\n",
    "\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "    .from_pretrained(\"google/mt5-small\", config=mt5_config)\n",
    "    .to(device)\n",
    ")\n",
    "#model = (AutoModelForSeq2SeqLM\n",
    "#         .from_pretrained(\"google/mt5-small\")\n",
    "#         .to(device))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  mt5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/756 [00:00<?, ?it/s]d:\\AI_project\\AI_env\\lib\\site-packages\\transformers\\generation\\utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "100%|██████████| 756/756 [10:35<00:00,  1.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.14073842505765038,\n",
       " 'rouge2': 0.06483047594077679,\n",
       " 'rougeL': 0.13820521347123615,\n",
       " 'rougeLsum': 0.1374925324295924}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "count = 0\n",
    "total_metrice = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "with open(\"test_nofinetuning.json\", 'w', encoding='UTF-8') as F:\n",
    "  for batch in tqdm(sample_dataloader):\n",
    "    count += 1\n",
    "    with torch.no_grad():\n",
    "      preds = model.generate(\n",
    "        batch[\"input_ids\"].to(device),\n",
    "        num_beams=10,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=1,\n",
    "        remove_invalid_values=True,\n",
    "        max_length=64,\n",
    "      )\n",
    "    labels = batch[\"labels\"]\n",
    "    met = metrics_func([preds, labels])\n",
    "    total_metrice['rouge1'] += met['rouge1']\n",
    "    total_metrice['rouge2'] += met['rouge2']\n",
    "    total_metrice['rougeL'] += met['rougeL']\n",
    "    total_metrice['rougeLsum'] += met['rougeLsum']\n",
    "    labels = np.where(labels != -100, labels, mt5_tokenizer.pad_token_id)\n",
    "    encode_preds = mt5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    encode_labels = mt5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    for pred, label in zip(encode_preds, encode_labels):\n",
    "      data = {\n",
    "        \"new_title\": pred,\n",
    "        \"old_title\": label\n",
    "      }\n",
    "      F.write(json.dumps(data , ensure_ascii=False) + \"\\n\")\n",
    "total_metrice['rouge1'] /= count\n",
    "total_metrice['rouge2'] /= count\n",
    "total_metrice['rougeL'] /= count\n",
    "total_metrice['rougeLsum'] /= count\n",
    "total_metrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"./ml_model\")\n",
    "         .to(device))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  mt5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 756/756 [15:00<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.38907452701776485, 'rouge2': 0.1944478298758119, 'rougeL': 0.3432992432870327, 'rougeLsum': 0.3604219622015408}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "count = 0\n",
    "total_metrice = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "with open(\"test_ml_model.json\", 'w', encoding='UTF-8') as F:\n",
    "  for batch in tqdm(sample_dataloader):\n",
    "    count += 1\n",
    "    with torch.no_grad():\n",
    "      preds = model.generate(\n",
    "        batch[\"input_ids\"].to(device),\n",
    "        num_beams=10,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=1,\n",
    "        remove_invalid_values=True,\n",
    "        max_length=64,\n",
    "      )\n",
    "    labels = batch[\"labels\"]\n",
    "    met = metrics_func([preds, labels])\n",
    "    total_metrice['rouge1'] += met['rouge1']\n",
    "    total_metrice['rouge2'] += met['rouge2']\n",
    "    total_metrice['rougeL'] += met['rougeL']\n",
    "    total_metrice['rougeLsum'] += met['rougeLsum']\n",
    "    labels = np.where(labels != -100, labels, mt5_tokenizer.pad_token_id)\n",
    "    encode_preds = mt5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    encode_labels = mt5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    for pred, label in zip(encode_preds, encode_labels):\n",
    "      data = {\n",
    "        \"new_title\": pred,\n",
    "        \"old_title\": label\n",
    "      }\n",
    "      F.write(json.dumps(data , ensure_ascii=False) + \"\\n\")\n",
    "total_metrice['rouge1'] /= count\n",
    "total_metrice['rouge2'] /= count\n",
    "total_metrice['rougeL'] /= count\n",
    "total_metrice['rougeLsum'] /= count\n",
    "print(total_metrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.38907452701776485, 'rouge2': 0.1944478298758119, 'rougeL': 0.3432992432870327, 'rougeLsum': 0.3604219622015408}\n"
     ]
    }
   ],
   "source": [
    "print(total_metrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"./mlrl_model\")\n",
    "         .to(device))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  mt5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 756/756 [17:14<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.4003866792449791, 'rouge2': 0.1988885625182064, 'rougeL': 0.3458343805309676, 'rougeLsum': 0.3694786485875702}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "count = 0\n",
    "total_metrice = {\n",
    "  'rouge1': 0,\n",
    "  'rouge2': 0,\n",
    "  'rougeL': 0,\n",
    "  'rougeLsum': 0\n",
    "}\n",
    "with open(\"test_mlrl_model.json\", 'w', encoding='UTF-8') as F:\n",
    "  for batch in tqdm(sample_dataloader):\n",
    "    count += 1\n",
    "    with torch.no_grad():\n",
    "      preds = model.generate(\n",
    "        batch[\"input_ids\"].to(device),\n",
    "        num_beams=10,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=1,\n",
    "        remove_invalid_values=True,\n",
    "        max_length=64,\n",
    "      )\n",
    "    labels = batch[\"labels\"]\n",
    "    met = metrics_func([preds, labels])\n",
    "    total_metrice['rouge1'] += met['rouge1']\n",
    "    total_metrice['rouge2'] += met['rouge2']\n",
    "    total_metrice['rougeL'] += met['rougeL']\n",
    "    total_metrice['rougeLsum'] += met['rougeLsum']\n",
    "    labels = np.where(labels != -100, labels, mt5_tokenizer.pad_token_id)\n",
    "    encode_preds = mt5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    encode_labels = mt5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    for pred, label in zip(encode_preds, encode_labels):\n",
    "      data = {\n",
    "        \"new_title\": pred,\n",
    "        \"old_title\": label\n",
    "      }\n",
    "      F.write(json.dumps(data , ensure_ascii=False) + \"\\n\")\n",
    "total_metrice['rouge1'] /= count\n",
    "total_metrice['rouge2'] /= count\n",
    "total_metrice['rougeL'] /= count\n",
    "total_metrice['rougeLsum'] /= count\n",
    "print(total_metrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.4003866792449791, 'rouge2': 0.1988885625182064, 'rougeL': 0.3458343805309676, 'rougeLsum': 0.3694786485875702}\n"
     ]
    }
   ],
   "source": [
    "print(total_metrice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
